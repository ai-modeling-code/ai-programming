{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H32W29hN8KSQ"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7giJIcp6sSA"
   },
   "source": [
    "# 3 프로젝트 모델 구현\n",
    "\n",
    "## 1 Data Loader 구현\n",
    "\n",
    "모델을 구현하기에 앞서 데이터를 가져올 Data Loader를 구현한다.\n",
    "\n",
    "### 1 구현할 메서드 살펴보기\n",
    "\n",
    "1. len\n",
    "\n",
    "batch가 몇 개 있는지 확인하는 메서드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9MPCPL46pbc"
   },
   "outputs": [],
   "source": [
    "def __len__(self):\n",
    "    return math.ceil(len(self.x) / self.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFRRySKd6vUN"
   },
   "source": [
    "2. getitem\n",
    "\n",
    "batch를 생성하는 메서드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExB2g9fZ60nF"
   },
   "outputs": [],
   "source": [
    "def __getitem__(self, idx):\n",
    "    strt = idx * self.batch_size\n",
    "    fin = (idx + 1) * self.batch_size\n",
    "    data = self.df.iloc[strt:fin]\n",
    "\n",
    "    batch_x, batch_y = self.get_data(data)\n",
    "\n",
    "    return np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S2PEUWA49-9G"
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# url = 'https://drive.google.com/file/d/1USSTL8IlR_gux_FAPFI4wpOkEdanxgPZ'\n",
    "# fname = 'oxford_pet.zip'\n",
    "# gdown.download(url, fname, quiet=False)\n",
    "# !unzip -qq /content/drive/MyDrive/oxford_pet.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSduM2vEAhQF"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/oxford_pet.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lZG7d95AqgQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkWiUz72Au93"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./annotations/list.txt', skiprows=6, delimiter=' ', header=None)\n",
    "\n",
    "# list.txt 안의 정보대로 파일 이름, id, species, breed 순서로 칼럼을 만들어 준다.\n",
    "df.columns = ['file_name', 'id', 'species', 'breed']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6S6Z_KS6240"
   },
   "source": [
    "### 2 Data Loader 구현하기\n",
    "\n",
    "대용량 데이터 세트를 배치 처리할 수 있도록 Data Loader를 구현해 보자.\n",
    "\n",
    "1. 라이브러리 import하기\n",
    "\n",
    "필요한 라이브러리를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3pAbRTU65hG"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kQYDYiF688R"
   },
   "source": [
    "2. Sequence 작성하기\n",
    "\n",
    "순서대로 코드를 작성해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de7O7RTc6_X9"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "# 객체 생성 시 필요한 인자 정하기\n",
    "# 배치 사이즈, 데이터를 폴더별로 저장했기 때문에 csv 파일 경로\n",
    "# fold\n",
    "# 학습인지를 다지는 mode\n",
    "    def __init__(self, batch_size, csv_path,\n",
    "                 fold, image_size, mode='train',\n",
    "                 shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.fold = fold\n",
    "        self.mode = mode\n",
    "        self.image_size = image_size # Added missing image_size assignment\n",
    "\n",
    "        # csv 파일 경로 가져오기\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "# mode에 따른 fold 나누기\n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "# 한 번씩 데이터 셔플해 주기\n",
    "        self.on_epoch_end()\n",
    "# batch가 몇 개 있는지 확인하기, 남는 데이터를 위해 올림 사용\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "# batch의 index를 input으로 받는다.\n",
    "# 예시 코드를 활용하여 작성한다.\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "\n",
    "        # get_data 함수 호출해 저장\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "# 데이터 안의 모든 이미지와 label을 읽어 온다.\n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "\n",
    "        for _, r in data.iterrows():\n",
    "            file_name = r['file_name']\n",
    "            # 경로에서 가져오기\n",
    "            image_path = f'./images/{file_name}.jpg'\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Check if the image was loaded successfully\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not load image from {image_path}. Skipping.\")\n",
    "                continue # Skip this iteration if image loading failed\n",
    "\n",
    "            # BGR -> RGB로 변경\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            # 사이즈 재지정\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "            # 이미지 픽셀을 0~255로 재지정\n",
    "            image = image / 255.\n",
    "\n",
    "            # 해당 이미지가 개인지, 고양인지 이진 분류(고양이 0, 강아지 1로 재지정)\n",
    "\n",
    "            label = int(r['species']) -1\n",
    "\n",
    "            batch_x.append(image)\n",
    "            batch_y.append(label)\n",
    "\n",
    "        return batch_x, batch_y\n",
    "# 콜백 메서드 작성, 셔플해 주는 함수\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG1WJDKb7BzJ"
   },
   "source": [
    "3. 동작 확인하기\n",
    "\n",
    "DataGenerator 객체를 생성해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-otVk2w7EVy"
   },
   "outputs": [],
   "source": [
    "csv_path = './kfolds.csv'\n",
    "train_generator = DataGenerator(\n",
    "# 시각화하려고 너무 크지 않게 9로 지정\n",
    "    batch_size=9,\n",
    "    csv_path=csv_path,\n",
    "# 첫 번째 fold로\n",
    "    fold=1,\n",
    "# 256 * 256로 구현\n",
    "    image_size=256,\n",
    "    mode='train',\n",
    "    shuffle=True\n",
    ")\n",
    "# 배치 사이즈가 9이므로 다시 9를 곱해 주면 5886이 나오는 것을 확인할 수 있다.\n",
    "print(len(train_generator)*9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuqUK3pD7F_o"
   },
   "source": [
    "4. 불러오기\n",
    "\n",
    "개와 고양이를 잘 분류하는지 이미지를 출력해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpJbLUI_7Obl"
   },
   "outputs": [],
   "source": [
    "class_name = ['Cat', 'Dog']\n",
    "\n",
    "for batch in train_generator:\n",
    "    X, y = batch\n",
    "    plt.figure(figsize=(15,15))\n",
    "    # 9개 배치이므로 9개를 가져온다.\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i+1)\n",
    "        plt.imshow(X[i])\n",
    "    # 각 타이틀에 맞게 개인지 고양이인지 적어 준다.\n",
    "        plt.title(class_name[y[i]])\n",
    "        plt.axis('off')\n",
    "\n",
    "    # 첫 번째 배치만 확인하고 종료\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34ryMzjs7RfX"
   },
   "source": [
    "## 2 모델 구현\n",
    "\n",
    "모델 구현에 가장 많이 사용하고 있는 케라스의 Sequence를 활용해 구현하고자 한다. 1개의 input과 1개의 output을 구현하기에 적합하다.\n",
    "\n",
    "### 1 구현할 메서드\n",
    "\n",
    "모델 구현에 앞서 구현할 메서드를 살펴보자.\n",
    "\n",
    "1. 라이브러리 가져오기\n",
    "\n",
    "필요한 라이브러리를 가져오고 사용할 GPU를 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POme2Ew-7SkP"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICE'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHZsEE2b7UP_"
   },
   "source": [
    "1. get_sequential_model\n",
    "\n",
    "Sequential 모델은 순차적으로 레이어 층을 더해 주는 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxjzANr97Wcw"
   },
   "outputs": [],
   "source": [
    "def get_sequential_model(input_shape):\n",
    "    model = keras.Sequential(\n",
    "        [ layers.Input(input_shape), # input\n",
    "          # 1st Conv block\n",
    "          layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.MaxPool2D(),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.5),\n",
    "          # 2nd Conv block\n",
    "          layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.MaxPool2D(),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.3),\n",
    "          # Classifier\n",
    "          layers.GlobalMaxPool2D(),\n",
    "          layers.Dense(128, activation='relu'),\n",
    "          layers.Dense(1, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh2mRQId7YaH"
   },
   "source": [
    "### 2 Sequence 작성하기\n",
    "\n",
    "순서대로 코드를 작성해 보자.\n",
    "\n",
    "1. 모델 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdnu7uTc7bQX"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICE'] = '1'\n",
    "\n",
    "def get_sequential_model(input_shape):\n",
    "    model = keras.Sequential(\n",
    "        [ layers.Input(input_shape), # input\n",
    "          # 1st Conv block\n",
    "          layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.Conv2D(64, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.MaxPool2D(),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.5),\n",
    "          # 2nd Conv block\n",
    "          layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.Conv2D(128, 3, strides=1, activation='relu', padding='same'),\n",
    "          layers.MaxPool2D(),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.3),\n",
    "          # Classifier\n",
    "          layers.GlobalMaxPool2D(),\n",
    "          layers.Dense(128, activation='relu'),\n",
    "          layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모양은 256x256x3(RGB)\n",
    "input_shape = (256, 256, 3)\n",
    "model = get_sequential_model(input_shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs5yCiGa7c-E"
   },
   "source": [
    "2. 학습 및 평가에 사용할 내용 정하기\n",
    "\n",
    "모델의 최적화 함수, 손실 함수, 측정 항목을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwvLxYYx7fPL"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'] # Changed to a list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qq_GqWOm7kP0"
   },
   "source": [
    "## 3 모델 학습\n",
    "\n",
    "구현한 모델을 가지고 실제로 학습해 본다.\n",
    "\n",
    "### 1 코드 작성하기\n",
    "\n",
    "1. 라이브러리 삽입 및 데이터 로드 코드 작성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wyUdzfl7mX3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "import pandas as pd # Import pandas\n",
    "import cv2 # Import cv2\n",
    "import math # Import math\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    # Corrected the typo from __init_ to __init__\n",
    "    def __init__(self, batch_size, csv_path, image_size,\n",
    "               fold, mode='train', shuffle=True):\n",
    "        self.batch_size =batch_size\n",
    "        self.image_size = image_size\n",
    "        self.fold = fold\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle # Add shuffle attribute assignment\n",
    "\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['fold'] != self.fold]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['fold'] == self.fold]\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.df) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        strt = idx * self.batch_size\n",
    "        fin = (idx + 1) * self.batch_size\n",
    "        data = self.df.iloc[strt:fin]\n",
    "\n",
    "        batch_x, batch_y = self.get_data(data)\n",
    "\n",
    "        # Ensure returned data is float32 for common model inputs\n",
    "        return np.array(batch_x, dtype=np.float32), np.array(batch_y, dtype=np.float32)\n",
    "\n",
    "\n",
    "    def get_data(self, data):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "\n",
    "        for _, r in data.iterrows(): # Corrected typo from iterrow to iterrows\n",
    "            file_name = r['file_name']\n",
    "\n",
    "            # Corrected typo from .jgp to .jpg and added check for image loading\n",
    "            image_path = f'./images/{file_name}.jpg'\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Add a check to ensure the image was loaded successfully\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not load image from {image_path}. Skipping.\")\n",
    "                continue # Skip this iteration if image loading failed\n",
    "\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
    "\n",
    "            # Scale pixel values to be between 0 and 1\n",
    "            image = image / 255.0\n",
    "\n",
    "            label = int(r['species']) - 1\n",
    "\n",
    "            batch_x.append(image)\n",
    "            batch_y.append(label)\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PutTI9he7om-"
   },
   "source": [
    "2. 훈련 데이터 및 평가 데이터 지정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4IZ1I797r1B"
   },
   "outputs": [],
   "source": [
    "# csv_path = './kfolds.csv'\n",
    "# train_generator = DataGenerator(\n",
    "#     fold=1, mode='train', csv_path=csv_path, batch_size=128,\n",
    "#     image_size=256, shuffle=True)\n",
    "\n",
    "# valid_generator = DataGenerator(\n",
    "#     fold=1, mode = 'val', csv_path=csv_path,\n",
    "#     batch_size=128, image_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Miw_INerCy_L"
   },
   "outputs": [],
   "source": [
    "csv_path = './kfolds.csv'\n",
    "train_generator = DataGenerator(\n",
    "    fold=1, mode='train', csv_path=csv_path, batch_size=64,  # Reduced batch size\n",
    "    image_size=256, shuffle=True)\n",
    "\n",
    "valid_generator = DataGenerator(\n",
    "    fold=1, mode = 'val', csv_path=csv_path,\n",
    "    batch_size=64, image_size=256, shuffle=True) # Reduced batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ycVBN7b7tl7"
   },
   "source": [
    "3. 학습하기\n",
    "\n",
    "훈련 데이터는 70% 정확도, 검증 데이터는 68% 정도의 정확도가 나왔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p37TtZ2n7yBd"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=3,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUjPvA1o70Jy"
   },
   "source": [
    "4. 훈련 결과 시각화하기\n",
    "\n",
    "훈련 데이터 및 검증 데이터의 정확도를 시각화하여 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhmLtHrm74Vi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = history.history\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history['accuracy'], label='train')\n",
    "plt.plot(history['val_accuracy'], label='val')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNCrNi6BC1iQzx1g6bnsHLg",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
